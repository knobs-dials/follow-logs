#!/usr/bin/python3
" Convenience around tail -F  and  journalctl  "
#

import os
import sys
import time
import re
import signal
import subprocess
import json
import argparse

try:
    import helpers_shellcolor as sc
except ImportError:
    sc = None

    
def print_message(source, message):
    " Unified pritner "
    # CONSIDER: detecting and doing 256 colors when we can
    # CONSIDER: I didn't I have a function for this?
    alisource = '%25s'%source
    if sc==None: # don't break if that color helper isn't there
        sys.stdout.write( alisource  )
    else:
        color_funcs = [ sc.blue, sc.red, sc.green, sc.cyan, sc.magenta, sc.yellow, sc.brightblue, sc.brightred, sc.brightcyan, sc.brightmagenta, sc.brightyellow, sc.brightgreen ]
        strhash = sum( ord(ch)  for ch in source )
        sys.stdout.write( color_funcs[strhash%len(color_funcs)]( alisource ) )
    sys.stdout.write( ': ')
    sys.stdout.write( message.rstrip() )
    sys.stdout.write( '\n')
    sys.stdout.flush()
    


    
class TailFollower(object):
    """ Imitation of tail -F, because actual tail -F seems to give up when we don't want it to.  Could stand some further testing.
    """
    def __init__(self):
        self.data = {} # filename -> ( fob, inode )
        
    def add_filename(self, filename):
        if not os.path.exists(filename):
            raise OSError('File does not exist')
        if filename not in self.data:
            ino = os.stat(filename).st_ino
            fob = open(filename)
            fob.seek(0,2)        
            self.data[filename] = (fob, ino)

    def remove_filename(self, filename):
        if filename in self.data:
            fob, ino = self.data[filename]
            fob.close()
        del self.data[filename]
        
    def update(self):
        ''' one cycle of dealing with what changed '''
        # should deal with
        # - filename disappearing, and later reappearing (os.path.exists False somewhere. inode is not relevant)
        # - file being replaced   (different inode; close and open)
        # ...largely because logrotate may cause both, depending on config and how fast it is
        
        for filename in sorted(self.data.keys()):
            #print( "checking %s"%filename )
            fob, ino = self.data[filename]

            if fob==None: # disappeared before, see if it reapeared
                if os.path.exists(filename):
                    print( "file reappeared, opening: %r"%filename )
                    fob = open(filename)
                    fob.seek(0,2)
                    ino = os.stat(filename).st_ino
                    self.data[filename] = (fob, ino)
                # CONSIDER: a (longish, configurable)  timeout to retry opens in
                
            else: # not marked disappeared

                try:
                    if not os.path.exists(filename):
                        print( "file disappeared, closing: %r"%filename )
                        fob.close()
                        self.data[filename] = (None, None)

                    else: # filename still exists, check for being replaecd (e.g. by logrotate)
                        stob = os.stat(filename)
                        if stob.st_ino != ino:
                            print( "file was replaced, reopening: %r"%filename )
                            fob.close()
                            fob = open(filename)
                            fob.seek(0,2)
                            self.data[filename] = (fob, stob.st_ino)


                    ### see if there are new lines to print
                    pos = fob.tell()
                    if pos != stob.st_size: # we assume things are only ever appended
                        if stob.st_size < pos: # ...mostly.
                            print( "file shrunk, seeking to end: %r"%filename )
                            fob.seek( 0,2 )
                        for line in fob.readlines():
                            print_message( os.path.basename(filename), line )
                            
                except (ValueError,) as e: # if the file disappears after the exists check, things like the tell and read will fail instead. TODO: figure out all possible exceptions
                    pass
                    
    def start_thread(self, interval_sec=0.5):
        " if you're not in a position to regularly call update(), you can get this thread to do it for you "
        import threading
        def threadfunc(ob):
            while True:
                ob.update()
                time.sleep( interval_sec )
        thr = threading.Thread(target=threadfunc, args=(self,), name='file_follow')
        thr.daemon = True # basically, don't be the reason Ctrl-C doesn't work
        thr.start()
        return thr
        



    
class JournalctlReader(object):
    def __init__(self):
        self.pid = None
        self.proc = None
        # TODO: take recency and turn into   --since "2 hours ago" style thing
        
    def change(self, units):
        if self.pid:
            os.kill( self.pid, signal.SIGKILL )
            self.proc.wait()

        cmd = ['/bin/journalctl',
            b'-o',b'json',
            #b'-n',b'10', # show n last entries
            b'-f'
        ]
        for unit in units:
            cmd.extend( ['-u', unit] )
        #print( cmd )
        self.proc = subprocess.Popen(cmd, shell=False, stdout=subprocess.PIPE)
        
    def update(self):
        ''' one cycle of dealing with what changed '''
        if self.proc != None:
            line = self.proc.stdout.readline() # delay in thread can be tiny because this blocks
            try:
                d = json.loads(line)

                msg  = d.get('MESSAGE')
                
                # I'm still figuring out which fields are present when (docs don't really say)
                
                #   and in the process, these are spammy:
                for debug_remove in ('__CURSOR', '__REALTIME_TIMESTAMP', '__MONOTONIC_TIMESTAMP', '_SOURCE_MONOTONIC_TIMESTAMP', '_BOOT_ID', '_MACHINE_ID', '_HOSTNAME'):
                    if debug_remove in d:
                        del d[debug_remove]

                transport = d.get('_TRANSPORT',None)
                if transport=='journal':
                    #print( d ) # figuring out the fields
                    sourcename = d.get('UNIT','unknown unit')        #sourcename = d.get('_SYSTEMD_UNIT',None) # this seems to be a scope. Um?
                    if sourcename.endswith('.service'):
                        sourcename = sourcename[:-8]
                        
                elif transport=='kernel':
                    #print( d ) # figuring out the fields
                    t = d.get('_KERNEL_SUBSYSTEM') # not always present
                    if t==None:
                        t = d.get('SYSLOG_IDENTIFIER') # may be 'kernel'
                    if t=='kernel':    
                        sourcename = 'kernel'
                    else:
                        sourcename = 'kernel/%s'%t

                elif transport=='syslog':
                    sourcename = 'syslog/%s'%d.get('SYSLOG_IDENTIFIER')

                elif transport=='stdout': # service's stdout, try to figure uot service name
                    #print( d ) # figuring out the fields
                    t = d.get('_SYSTEMD_UNIT') # not always present
                    if t==None:
                        t = d.get('SYSLOG_IDENTIFIER') # may be 'kernel'
                    if t!=None:
                        if t.endswith('.service'):
                            t = t[:-8]
                        sourcename = '%s'%t
                    else:
                        sourcename = 'stdout'
                    if type(msg) is type([]): # what the hell?
                        msg = bytes(msg).decode('u8') # decode u8 is a guess, maybe add fallback
                
                elif transport=='driver':
                    #print( d ) # figuring out the fields
                    sourcename = 'driver'
                    
                elif transport=='audit':
                    #print( d ) # figuring out the fields
                    sourcename = 'audit'                    
                else: # right now no others exist (accordign to docs, at least)
                    #print( d ) # figuring out the fields
                    sourcename = transport

                    
                print_message( '[%s]'%sourcename, msg )

            except (ValueError, KeyError) as e:
                print( e )
                pass

    def start_thread(self):
        " if you're not in a position to regularly call update(), you can get this thread to do it for you "
        import threading
        def threadfunc(ob):
            while True:
                ob.update()
                #time.sleep( interval_sec )
        thr = threading.Thread(target=threadfunc, args=(self,), name='journalctl_follow')
        thr.daemon = True # basically, don't be the reason Ctrl-C doesn't work
        thr.start()
        return thr



########################################################################

try: 
    import setproctitle    # I like my tmux titles informative
    setproctitle.setproctitle( os.path.basename(sys.argv[0]) )
except ImportError:
    pass


# CONSIDER: make members of main class, the scopey references are a little ugly
tf = TailFollower()
tf.start_thread( )

jr = JournalctlReader()
jr.start_thread( )




# helpers for log files        

def path_indicates_possible_log(filepath):
    """ Filename-based guess of whether this is likely to be a lof file.
        Used to clean up entries from homedirs and other places where you may see a lot of non-logs
    """
    # whitelist things we want to check
    if re.compile(r'\blog').search(filepath):
        return True 
    if filepath.endswith('.OU') or filepath.endswith('.ER'):  # Torque PBS's convention
        return True
    if filepath.endswith('.gz') or filepath.endswith('.bz2'): 
        return False
    # Blacklist common files that won't be logs.   Never a complete list, but speeds up what it can
    if (filepath.endswith('.rb')  or filepath.endswith('.gemspec') or filepath.endswith('.conf') or
        filepath.endswith('.cpp') or filepath.endswith('.py')      or
        filepath.endswith('.svn-base') or filepath.endswith('.html')    or
        filepath.endswith('.gif') or filepath.endswith('.jpg')     or filepath.endswith('.png')
        ):
        return False
    return False


def is_recent(filename, recency_minutes=60):
    ''' Returns true if the youngest of (mtime,ctime) for the file is no longer than some amount of minutes ago, compared to the system clock. '''
    stob = os.stat(filename)
    latest_time = max([stob.st_mtime,stob.st_ctime])
    tdiff_sec = int(time.time()-latest_time)
    #print( filename )
    #print( 'latest change: %s'%latest_time )
    #print( 'time ago:      %s hours '%round(tdiff_sec/3600., 1) )
    if tdiff_sec < (60.*recency_minutes):
        return True
    return False


def is_nonbinary(filename=None, data=None, amt=200):
    """ Given either a filename or some data from it, returns whether this is probably text, rather than binary data.
        amt: controls how much of data we use (or how much to read from the filename)

        Written for 'is this possibly a log' test, so specialcases compressed files because of log rotation.
    """
    if data==None:
        if filename==None:
            raise ValueError("You need to give either a filename or some of the file's content data")
        else:
            f=open(filename,'rb')
            data=f.read(amt)
            f.close()

    if data[:2]==b'\x1f\x8b': # gzip magic
        #print( 'Ignoring %r, is Gzip'%filename )
        return False
    elif data[:3]==b'BZh':    # bzip2 magic.  There's also 'BZ0' for bzip1, but meh.
        #print( "Ignoring %r, is bzip2"%filename )
        return False
    elif data[:3]==b'\xFD\x37\x7A\x58\x5A\x00':    # xz magic (TODO: test)
        #print( "Ignoring %r, is xz"%filename )
        return False

    # list of ordinals
    ol = list(ch  for ch in data[:amt]) # ord in py2
    printable,nonprintable=0,0
    for o in ol:
        if (o>=0x20 and o<0x7f) or o in (0x0d, 0x0a):
            printable    += 1
        else:
            nonprintable += 1

    #print(filename, printable, nonprintable )
    if nonprintable==0: #only printable - this is text.
        return True
    else:
        # could be made slightly cleverer, but this is probably enough.
        printable_ratio = float(printable)/float(nonprintable+printable)
        if printable_ratio>0.95: # assume that's enough
            return True
        else:
            return False

def islogfile_cheapguess(filename=None,data=None, amt=200):
    return is_nonbinary(filename, data, amt)




class Rescanner(object):
    ''' The bulk of the logic checking for new files and new units. '''
    def __init__(self,
                 scan_dirs=[b'/var/log'],
                 add_home=False,
                 onlys=None,
                 nots=None,                 
                 recency_minutes=24.0*60.,
                 check_interval_sec=20,
                 nomatch_rescan_interval_sec=5,
                 verbose=False,
                 ):
        """ Constructor takes most settings.
            add_home         - look in current user's home directory
            recency_minutes  - log needs to be this young to be listed.   0/False/None means don't filter. 

            If onlys isn't None or [], it is used as a whitelist of substrings
            that have to appear somewhere in the path.
            This lets you easily filter for some specific named logs (or directories)
        """
        self.verbose = verbose

        self.add_home = add_home
        self.log_filenames = []
        self.saw_new_filenames = False
        self.scan_dirs = scan_dirs
        self.recency_minutes = recency_minutes
        
        self.onlys = onlys
        self.nots = nots
        
        if check_interval_sec!=None:
            check_interval_sec = max(1,check_interval_sec) # less than 1 second makes little sense.
        self.check_interval_sec = check_interval_sec
        self.nomatch_rescan_interval_sec = nomatch_rescan_interval_sec
        
        proc = subprocess.Popen(['/usr/bin/which', 'systemctl'], stdout=subprocess.PIPE )
        out1, _ = proc.communicate()
        self._systemctl_path = out1.strip()
        self.is_systemd = (self._systemctl_path != '')
        self.log_units = []
        
        
    def journalctl_list(self, striptype=False):
        """ in class so we can reuse detected paths  """
        proc = subprocess.Popen([self._systemctl_path, b'list-units', b'--type=service',
                                     b'--plain', b'--no-legend',  # easier to parse
                                     b'--all'                     # not just active
                                     ], stdout=subprocess.PIPE )
        out, _ = proc.communicate()
        ret = []
        for line in out.splitlines():
            line = line.rstrip().decode('utf-8')  # encode: subprocess gives bytes, we're about to filter by cmdline arguments which are unicode
            unit, load, active, sub, description = line.split(None, 4)
            typeless, _ = unit.rsplit('.',1)
            if striptype: # from returned unit names
                unit = typeless

            if self.onlys!=None and len(self.onlys)>0:
                whitelist_condition = False
                for filtstr in self.onlys:
                    if filtstr in typeless:
                        whitelist_condition = True
                        break
                if not whitelist_condition:
                    if self.verbose:
                        print( "%60r  Doesn't match whitelist"%unit )
                    continue

            if self.nots!=None and len(self.nots)>0:
                blacklist_condition = False
                for filtstr in self.nots:
                    if filtstr in typeless:
                        blacklist_condition=True
                        break
                if blacklist_condition:
                    if self.verbose:
                        print( "%60r  Matches blacklist"%unit )
                    continue
            
            ret.append(unit)            
        return ret
    

    def rescan_systemdunits(self):
        if not self.is_systemd: # avoid work when we never found systemctl
            return
        #TODO: integrate proper whitelist/blacklist logic
        units_now = self.journalctl_list()
        new_units = set(units_now).difference( self.log_units )
        if len(new_units)==0:
            self.saw_new_units = False
        else:
            self.saw_new_units = True
            if self.verbose:
                print( "New units turned up: %s"%new_units )
                print( "  unit set now %s"%units_now )
        self.log_units = units_now

        
    
    def rescan_filelogs(self):
        """ Scans for logs with the configuration as listed in the obeject.
            Returns matching filenames.
        """
        if self.verbose:
            if self.recency_minutes:
                print( "Finding recently used files that look like logs..." )
            else:
                print( "Finding files that look like logs..." )
            
        justnow_filenames = []
        
        if self.add_home: # TODO: we may want more restrictions here, e.g. looking only for filenames ending in .log
            scan_dirs.append( os.path.expanduser('~') )
        
        for scan_dir in self.scan_dirs:
            if self.verbose:
                print( "\n ...in %s"%scan_dir )
            try:
                # this indexing also does most filtering
                sawfiles_num = 0
                for curdir, _, files in os.walk( os.path.abspath(scan_dir) ):
                    for filename in files:
                        fullpath = os.path.join(curdir,filename)
                        sawfiles_num += 1
                    
                        # ONLY if whitelist is specified do we use it as a "only allow things that are in this"
                        # (so it's white+black, all+black, or neither)
                        if self.onlys!=None and len(self.onlys)>0:
                            whitelist_condition = False
                            for filtstr in self.onlys:
                                #print('%r %r'%(filtstr,fullpath))
                                if filtstr in fullpath:
                                    whitelist_condition = True
                                    break
                            if not whitelist_condition:
                                if self.verbose:
                                    print( "%60r  Doesn't match whitelist"%fullpath )
                                continue
                        
                        if self.nots!=None and len(self.nots)>0:
                            blacklist_condition = False
                            for filtstr in self.nots:
                                if filtstr in fullpath:
                                    blacklist_condition=True
                                    break
                            if blacklist_condition:
                                if self.verbose:
                                    print( "%60r  Matches blacklist"%fullpath)
                                continue
                        
                        # above the content guess. when this applies, we avoid file operations
                        if self.recency_minutes:
                            if not is_recent(fullpath, recency_minutes=recency_minutes):
                                if self.verbose:
                                    print( "%60r  Not recent"%fullpath )
                                continue

                        is_log = islogfile_cheapguess(filename=fullpath)
                        if is_log:
                            if self.verbose:
                                print( "%60r  Looks good"%fullpath )
                            justnow_filenames.append(fullpath)
                        else:
                            if self.verbose:
                                print( "%60r  Does not look like log  (or is compresed)"%fullpath )
                if self.verbose:
                    print("scanned %d files for logness"%sawfiles_num)
                                
            except Exception as exception:
                #if self.verbose:
                sys.stderr.write( "Error (%s), ignoring..."%str(exception))
                raise

        if self.verbose:           
            print( "\nDone, found %d logs"%len(justnow_filenames) )

        # Check whether we saw new filenames
        #   we only care about seeing files we had not seen before,
        #   as tail deals with and mentions disappearance, and now-silent logs are not shown.
        new_files = set(justnow_filenames).difference( self.log_filenames )
        if len(new_files)==0:
            self.saw_new_filenames = False
        else:
            self.saw_new_filenames = True                        
        self.log_filenames = justnow_filenames


    def scan_and_follow(self):
        """ Scans, runs a tail subprocess on the result.
        """
        while True:
            # updates some of our state
            self.rescan_systemdunits()                    
            self.rescan_filelogs()     

            if len(self.log_filenames)==0 and len(self.log_units)==0: # no matching logs at all.
                # Usually means no matches when starting up because of overly strict filters
                # can also mean all matching logs were removed.
                # In either case, we keep rescanning
                print( "No matching logs, waiting until some do" )
                # note: will skip both blocks below and do only the interval sleep

            if self.verbose:
                print( "\nMatching log files: %r"%self.log_filenames )
                print( "\nMatching systemd units: %r"%self.log_units )

            if not (self.saw_new_filenames or self.saw_new_units): # ...but nothing changed. Do nothing.
                if self.verbose:
                    print( "\nNo changes in matching logs" )
                # note: will skip both blocks below and do only the interval sleep
            else:
                
                if self.saw_new_units:
                    #if self.verbose:
                    sys.stdout.write( 'Changing journalctl to listen to %d units\n'%len(self.log_units) )
                    sys.stdout.flush()
                    jr.change( self.log_units )

                if self.saw_new_filenames:
                    sys.stdout.write( 'Changing tail to listen to %d files\n'%len(self.log_filenames) )
                    sys.stdout.flush()
                    for filename in self.log_filenames: # thigns we already listen to will be ignored
                        tf.add_filename( filename )
            
            ### 
            if self.verbose:
                print( "Sleeping %.1f"%self.check_interval_sec )
            time.sleep( self.check_interval_sec )



                    

if __name__=='__main__':
    def parse_hms(v):
        ''' string interval spec to seconds, e.g.  
             '1h30m' -> 5400, 
             '1 day, 30 min, 4 sec' -> 88204
            Very naive implementation (just looks for words starting with w,d,h,m,s)
        '''
        ret_sec = 0
        things = re.findall(r'([0-9.]+)\s*([a-z]+)[,;\s-]*', v.lower())
        if len(things)==0:
            try:
                ret_sec = float(v) # see if it's unitless, interpret as seconds
            except:
                raise ValueError("don't understand value %r"%unit)
        for num,unit in things:
            #print num,unit
            n = float(num)
            if unit[0]=='w':
                n *= 60*60*24*7
            elif unit[0]=='d':
                n *= 60*60*24
            elif unit[0]=='h':
                n *= 60*60
            elif unit[0]=='m':
                n *= 60
            elif unit[0]=='s':
                pass
            else:
                raise ValueError("don't understand time unit %r"%unit)
            ret_sec += n
        return ret_sec
    

    try:
        parser = argparse.ArgumentParser()
        parser.add_argument('-o',"--onlys",     action="store",       default=None,  help="if specified, matches only names with one of these substrings (comma separated)")
        parser.add_argument('-n',"--nots",      action="store",       default=None,  help="if specified, everything except names with one of these substrings (comma separated)")
        parser.add_argument("--recency",        action="store",       default="1w",  help="ignore logs with mtime/ctime older than this")
        parser.add_argument("--check-interval", action="store",       default="30s", help="check for log source changes every this often")
        parser.add_argument("--scandirs",       action="store",       default="/var/log/,/var/lib/log/",  help="paths to look for logs under, comma-separated, defaults to /var/log/,/var/lib/log/ ")
        parser.add_argument("--home",           action="store_true",  default=False, help="look for log-ish text files in homedir, defaults off since it's slow and may turn up crud.")
        parser.add_argument('-v', "--verbose",  action="store_true",  default=False,  help="debug verbosity")
        args = parser.parse_args()
        
        check_interval  = parse_hms( args.check_interval )
        recency_minutes = parse_hms( args.recency ) / 60.
        scan_dirs       = args.scandirs.split(',')
        #if 'cluster-log' in sys.argv[0]: # different behaviour if executable is linked as a different name
        #    scan_dirs = []
        #    add_home = 1
        onlys, nots = [], []
        if args.onlys:
            onlys = args.onlys.split(',')
        if args.nots:
            nots  = args.nots.split(',')
            
        if 0:
            print( check_interval )
            print( recency_minutes )
            print( scan_dirs )
            print( onlys )
            print( nots )
        
        s = Rescanner( scan_dirs          = scan_dirs,
                       add_home           = args.home,
                       recency_minutes    = recency_minutes,
                       check_interval_sec = check_interval,
                       onlys              = onlys,
                       nots               = nots,
                       verbose            = args.verbose,
        )
        
        print( "Looking for logs..." )
        s.scan_and_follow()

        
    except KeyboardInterrupt:
        pass
        # shutdown threads?

